<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Install OpenShift's Web Terminal Operator in any namespace</title><link rel="alternate" href="https://developers.redhat.com/articles/2021/12/14/install-openshifts-web-terminal-operator-any-namespace" /><author><name>Josh Pinkney</name></author><id>bdfbcf50-b931-4049-b61a-22151f7aa4e9</id><updated>2021-12-14T07:00:00Z</updated><published>2021-12-14T07:00:00Z</published><summary type="html">&lt;p&gt;The Web Terminal Operator in &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; provides a web terminal with common cluster tooling pre-installed. The operator gives you the power and flexibility to work with your product directly through the OpenShift web console, eliminating the need to have all your tooling installed locally.&lt;/p&gt; &lt;p&gt;This article is an overview of the new features introduced in Web Terminal Operator 1.4. One of the most important improvements is that you can now install the Web Terminal Operator in any namespace. In addition, our tooling has been updated to be compatible with OpenShift 4.9.&lt;/p&gt; &lt;h2&gt;Install the Web Terminal Operator in any namespace&lt;/h2&gt; &lt;p&gt;Previously, the Web Terminal Operator had to be installed in the &lt;code&gt;openshift-operators&lt;/code&gt; namespace in order to successfully interface with the OpenShift console. As of OpenShift 4.9, we've made changes to both the OpenShift console and the Web Terminal Operator to allow the Web Terminal Operator to work when installed not just in &lt;code&gt;openshift-operators&lt;/code&gt;, but in any other namespace as well.&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: If you decide to install the operator in a namespace other than &lt;code&gt;openshift-operators&lt;/code&gt;, be aware that this comes with some security risks. Anyone who has access to the namespace where the Web Terminal Operator is installed can change default tooling images.&lt;/p&gt; &lt;p&gt;If you are looking to enable this feature, you must create an operator group and a subscription through YAML, as illustrated in the listing below, rather than through the OpenShift UI.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;# Create the new namespace oc new-project new-web-terminal-operator-namespace # Create the operator group cat &lt;&lt;EOF | oc apply -f - apiVersion: operators.coreos.com/v1 kind: OperatorGroup metadata: name: web-terminal-non-openshift-operators EOF # Create the subscription cat &lt;&lt;EOF | oc apply -f - apiVersion: operators.coreos.com/v1alpha1 kind: Subscription metadata: name: web-terminal spec: channel: fast installPlanApproval: Automatic name: web-terminal source: redhat-operators sourceNamespace: openshift-marketplace startingCSV: web-terminal.v1.4.0 EOF &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Tooling update&lt;/h2&gt; &lt;p&gt;We have updated the default binaries in Web Terminal Operator 1.4 to include the latest versions of the built-in command-line tools, as shown in Table 1.&lt;/p&gt; &lt;p class="Indent1"&gt;Table 1. Command-line tools in Web Terminal Operator 1.4.&lt;/p&gt; &lt;div&gt; &lt;table cellspacing="0" width="388"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Binary&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;Old version&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;strong&gt;New version&lt;/strong&gt;&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;oc&lt;/code&gt;&lt;/td&gt; &lt;td&gt;4.8.2&lt;/td&gt; &lt;td&gt;4.9.0&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;odo&lt;/code&gt;&lt;/td&gt; &lt;td&gt;2.2.3&lt;/td&gt; &lt;td&gt;2.3.1&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;knative&lt;/code&gt;&lt;/td&gt; &lt;td&gt;0.21.0&lt;/td&gt; &lt;td&gt;0.23.0&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;tekton&lt;/code&gt;&lt;/td&gt; &lt;td&gt;0.17.2&lt;/td&gt; &lt;td&gt;0.19.1&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;rhoas&lt;/code&gt;&lt;/td&gt; &lt;td&gt;0.25.0&lt;/td&gt; &lt;td&gt;0.34.2&lt;/td&gt; &lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;code&gt;submariner&lt;/code&gt;&lt;/td&gt; &lt;td&gt;0.9.1&lt;/td&gt; &lt;td&gt;0.10.1&lt;/td&gt; &lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt; &lt;h2&gt;Additional resources&lt;/h2&gt; &lt;p&gt;For a peek into how the Web Terminal Operator works under the hood, please see &lt;a href="http://www.openshift.com/blog/a-deeper-look-at-the-web-terminal-operator-1"&gt;A deeper look at the Web Terminal Operator&lt;/a&gt; by Angel Misevski. Joshua Wood's initial release article, &lt;a href="https://developers.redhat.com/blog/2020/10/01/command-line-cluster-management-with-red-hat-openshifts-new-web-terminal-tech-preview"&gt;Command-line cluster management with Red Hat OpenShift’s new web terminal&lt;/a&gt;, is worth a read as well. You can also refer to our previous release blog, &lt;a href="https://developers.redhat.com/articles/2021/08/19/cluster-tooling-updates-and-more-red-hat-openshifts-web-terminal-operator-13"&gt;What's new in Red Hat OpenShift's Web Terminal Operator 1.3&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/12/14/install-openshifts-web-terminal-operator-any-namespace" title="Install OpenShift's Web Terminal Operator in any namespace"&gt;Install OpenShift's Web Terminal Operator in any namespace&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Josh Pinkney</dc:creator><dc:date>2021-12-14T07:00:00Z</dc:date></entry><entry><title type="html">Eclipse Vert.x 4.2.2 released!</title><link rel="alternate" href="https://vertx.io/blog/eclipse-vert-x-4-2-2" /><author><name>Julien Viet</name></author><id>https://vertx.io/blog/eclipse-vert-x-4-2-2</id><updated>2021-12-14T00:00:00Z</updated><content type="html">Eclipse Vert.x version 4.2.2 has just been released.</content><dc:creator>Julien Viet</dc:creator></entry><entry><title type="html">KIE &amp;amp; Log4j2 exploit CVE-2021-44228</title><link rel="alternate" href="https://blog.kie.org/2021/12/kie-log4j2-exploit-cve-2021-44228.html" /><author><name>Mario Fusco</name></author><id>https://blog.kie.org/2021/12/kie-log4j2-exploit-cve-2021-44228.html</id><updated>2021-12-13T18:25:30Z</updated><content type="html">2.x is a widely used Java logging framework. Unfortunately a few days ago it has been exposed to an important (“Log4Shell”, CVE-2021-44228).  The whole KIE ecosystem (Kogito, Drools, OptaPlanner and jBPM) moved to , a different logging facade with Logback as default implementation, a few years ago and it is therefore not vulnerable by CVE-2021-44228. Accordingly, our recommendation is to ensure your applications are updated to the latest community versions (at the time of writing, Drools, jBPM, KIE Workbench/Business Central and KIE Server 7.62.0.Final, Kogito 1.14.1.Final, Optaplanner 8.14.0.Final). Therefore if you’re using KIE projects as libraries in your projects you are not affected by this problem. Note that the , only declares the Log4j2 dependency management without actually depending on it. Dashbuilder is a monitoring component included in Business Central. We are about to just in case. In case you’re declaring and/or using Log4j2 dependency in your own KIE projects, please make sure to upgrade Log4j2 as soon as possible to version 2.15.0 which solves this problem.  We invite you to monitor this blog post, which will be updated in case of any future additional findings. Further readings: Update note: We found that Dashbuilder brought in log4j-core as a transitive dependency from the module uberfire-metadata-backend-elasticsearch and it has been . The latest version of KIE Workbench/Business Central containing it was 7.46.0.Final. Update note 2: As reported , the fact that WildFly distribution, and then also KIE Workbench/Business Central one which is based on it, contains the log4j-api artifact does not have any security implication. In fact the vulnerable code is only present in the log4j-core module which is not part of the distribution. The post appeared first on .</content><dc:creator>Mario Fusco</dc:creator></entry><entry><title type="html">How to handle Log4j CVE-2021-44228</title><link rel="alternate" href="http://www.mastertheboss.com/jbossas/jboss-log/how-to-handle-cve-2021-44228-in-java-applications/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=how-to-handle-cve-2021-44228-in-java-applications" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/jbossas/jboss-log/how-to-handle-cve-2021-44228-in-java-applications/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=how-to-handle-cve-2021-44228-in-java-applications</id><updated>2021-12-13T17:14:36Z</updated><content type="html">This short articles discussed the recent flaw in Log4j2 library which affects some recent versions of this opensource library. Let’s see how to perform checks and mitigation actions if your Java applications are using a flawed Log4j2 version. As discussed in this CVE there is a flaw in certain Log4j2 versions: From 2.0.0 to version ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">Infinispan and Log4j CVE-2021-44228</title><link rel="alternate" href="https://infinispan.org/blog/2021/12/13/infinispan-log4j-cve-releases" /><author><name>Tristan Tarrant</name></author><id>https://infinispan.org/blog/2021/12/13/infinispan-log4j-cve-releases</id><updated>2021-12-13T12:00:00Z</updated><content type="html">Dear Infinispan community, We’ve just released , and to address the . Additionally, we have released upgraded versions of the Infinispan Operator to match the server versions: 2.2.2.Final for Infinispan 13.0 and 2.1.6.Final for Infinispan 12.1. Please upgrade as soon as you can. Refer to our for versions. WHAT’S AFFECTED We include log4j-core in our server distributions, including the . We are fixing the issue by upgrading to Log4J 2.15.0. MITIGATION STRATEGIES If you cannot upgrade, there are a several you can apply. But upgrading is always the best solution.</content><dc:creator>Tristan Tarrant</dc:creator></entry><entry><title>Remote debugging on Kubernetes using VS Code</title><link rel="alternate" href="https://developers.redhat.com/articles/2021/12/13/remote-debugging-kubernetes-using-vs-code" /><author><name>Alberto Morgante Medina</name></author><id>00d09cfb-9482-4295-ab12-c75b1914eac2</id><updated>2021-12-13T07:00:00Z</updated><published>2021-12-13T07:00:00Z</published><summary type="html">&lt;p&gt;These days, most developers &lt;a href="topics/developer-tools"&gt;deploy applications&lt;/a&gt; on &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;. Debugging in a container environment can be hard, and developers sometimes resort to ineffective methods to discover bugs during the deployment phase. As an example, imagine that you have a &lt;a href="https://developers.redhat.com/topics/kubernetes/operators"&gt;Kubernetes Operator&lt;/a&gt; that you want to debug because the reconciliation process is not working properly, or because the operator is not working as expected. You decide to deploy the operator on a Kubernetes cluster running on your local machine, to verify what's happening in your production cluster.&lt;/p&gt; &lt;p&gt;At this point, you can write some code to debug the operator, build the new debug image, and deploy it on the local cluster to check the output and logs. More elegantly, you can use a debugger on a remote server, setting a breakpoint to look for the problematic behavior.&lt;/p&gt; &lt;p&gt;This article shows how to use the second option, running a debugger on Kubernetes through the &lt;a href="https://code.visualstudio.com"&gt;Visual Studio Code&lt;/a&gt; (VS Code) IDE. We'll debug a &lt;a href="https://developers.redhat.com/topics/go"&gt;Go&lt;/a&gt; program, but the principles apply to other languages and debuggers.&lt;/p&gt; &lt;h2&gt;Debugging options&lt;/h2&gt; &lt;p&gt;First, let's analyze the basics of the debugging methods I mentioned in order to understand the advantages of the method I chose.&lt;/p&gt; &lt;h3&gt;Debugging using output&lt;/h3&gt; &lt;p&gt;Reviewing output is the simplest way to deploy and debug an application or operator. You just need to identify the hot points in the code and print the information you want to debug. Piece of cake!&lt;/p&gt; &lt;p&gt;The problem with this procedure is the time required to build a new image each time you want to print new information. You also have to consider the time required to deploy the operator to your cluster before testing it.&lt;/p&gt; &lt;p&gt;For example, with the reconcile loops of complex operators (more than a thousand lines per reconcile loop), it could be difficult to print the exact information you need. It might take you several tries until you locate the issue and can debug it. Using print statements, you can easily miss the hot points and fail to see the information you need. In short, you could waste a lot of time with this method if you don't have a good understanding of the code.&lt;/p&gt; &lt;h3&gt;Debugging on a remote server&lt;/h3&gt; &lt;p&gt;This method consists of using a classical debugger to get information that reveals the cause of your problem quickly. The process shown in this article runs on the remote server in Kubernetes (maybe in a staging environment similar to the production environment). Furthermore, you are creating the images at the same time as you're fixing the code, deploying the operator again and again, and reducing the time you have to wait for information.&lt;/p&gt; &lt;p&gt;The key traits of this method are:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Running remotely on a test, staging, or production environment.&lt;/li&gt; &lt;li&gt;Using an interactive debugger (in this article, we use &lt;a href="https://golang.cafe/blog/golang-debugging-with-delve.html"&gt;Delve&lt;/a&gt; on a Go program).&lt;/li&gt; &lt;li&gt;Building and deploying the images automatically at the same time as you're running the debugger.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Let's get started.&lt;/p&gt; &lt;h2&gt;Prerequisites and environment options&lt;/h2&gt; &lt;p&gt;This section covers how to set up the environment and tools you need to run the example in this article. You'll run a Kubernetes cluster remotely on another server, using VS Code extensions to run the debugger and application remotely. My basic environment consists of:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;My laptop: &lt;ul&gt;&lt;li&gt;Operating system: macOS Big Sur 11.6&lt;/li&gt; &lt;li&gt;VS Code IDE and extensions&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;This is my laptop with VS Code installed, but without deployment tools such as Docker, &lt;code&gt;kubectl&lt;/code&gt;, and so on.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Server (hostname &lt;code&gt;alkmini&lt;/code&gt;): &lt;ul&gt;&lt;li&gt;&lt;a href="https://developers.redhat.com/topics/linux"&gt;Linux&lt;/a&gt; (Fedora 5.11.8-200.fc33.x86_64)&lt;/li&gt; &lt;li&gt;SSH server&lt;/li&gt; &lt;li&gt;Docker daemon running&lt;/li&gt; &lt;li&gt;&lt;code&gt;kubectl&lt;/code&gt; and &lt;code&gt;oc&lt;/code&gt; (the command-line interface for &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt;)&lt;/li&gt; &lt;li&gt;Delve (the debugger for Go)&lt;/li&gt; &lt;li&gt;A Kubernetes cluster (using &lt;code&gt;minikube&lt;/code&gt; for this example)&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;For the remote server, you could also use a staging cluster, a local cluster, or some other setup. The important points here are:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;On the local system, all you need is your IDE.&lt;/li&gt; &lt;li&gt;On the remote server, you don't need the IDE.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Installing VS Code extensions and tools&lt;/h2&gt; &lt;p&gt;First, install the VS Code extensions that allow you to run everything remotely.&lt;/p&gt; &lt;h3&gt;Remote - SSH&lt;/h3&gt; &lt;p&gt;This extension allows you to use VS Code on your laptop to work in a remote server exactly as you would use VS Code on your local machine. The extension uses SSH to connect to the remote server and run commands there, as well as use other VS Code extensions there.&lt;/p&gt; &lt;p&gt;Install the &lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-ssh"&gt;Remote - SSH extension&lt;/a&gt; from the Visual Studio marketplace.&lt;/p&gt; &lt;p&gt;Add your remote server and open a folder just like a workspace to start working remotely. Add your host information and ensure you have direct SSH access to the host (through a previously added SSH key). Then, you can navigate to the folder you want to add, as shown in Figure 1.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/k8s-fig1.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/k8s-fig1.png?itok=vvYd0l7F" width="408" height="530" alt="The Remote - SSH extension allows access to files on your remote system just like a local system." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1. The Remote - SSH extension allows access to files on your remote system just like a local system. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Once connected, you can tell that you're working remotely because an SSH connection appears in green in the left-hand bottom corner of the screen, as shown in Figure 2.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/k8s-fig2.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/k8s-fig2.png?itok=TVoAYzaw" width="600" height="84" alt="When you work remotely, the SSH connection is shown at the bottom left-hand corner of the screen." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2. When you work remotely, the SSH connection is shown at the bottom left-hand corner of the screen. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;At this point, everything you do in your laptop VS Code editor is executed in the remote server.&lt;/p&gt; &lt;p&gt;Think about which extensions you need in the remote server. What you install in the remote server will probably be only a subset of extensions installed on your own system.&lt;/p&gt; &lt;h3&gt;Cloud Code Kubernetes&lt;/h3&gt; &lt;p&gt;This extension provides local, continuous feedback on your project as you edit, build, deploy, and run your applications locally or in the cloud. The extension works under the hood with Google’s command-line container tools such as &lt;a href="https://skaffold.dev/docs/install/"&gt;Skaffold&lt;/a&gt;, &lt;a href="https://minikube.sigs.k8s.io/docs/start/"&gt;minikube&lt;/a&gt;, and &lt;a href="https://kubernetes.io/docs/reference/kubectl/overview/"&gt;kubectl&lt;/a&gt;. Cloud Code was originally designed to be used with the Google Cloud Platform, but it works on any Kubernetes cluster. We'll use Cloud Code with our &lt;code&gt;minikube&lt;/code&gt; Kubernetes cluster.&lt;/p&gt; &lt;p&gt;Install the &lt;a href="https://marketplace.visualstudio.com/items?itemName=GoogleCloudTools.cloudcode"&gt;Cloud Code extension&lt;/a&gt; from the Visual Studio marketplace.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: As of this writing, there is a &lt;a href="https://github.com/GoogleCloudPlatform/cloud-code-vscode/issues/486"&gt;bug&lt;/a&gt; in the latest version, so you need to install the previous version, Cloud Code 1.14.1.&lt;/p&gt; &lt;h3&gt;Delve&lt;/h3&gt; &lt;p&gt;Delve (&lt;code&gt;dlv&lt;/code&gt;) is the official debugger for the Go programming language. Delve should be easy to invoke and use, and provides a simple, full-featured debugging tool for Go. Chances are that when you're using a debugger, things aren't going well. With that in mind, Delve tries to stay out of your way as much as possible.&lt;/p&gt; &lt;p&gt;Install Delve from &lt;a href="https://github.com/go-delve/delve/tree/master/Documentation/installation"&gt;the repository on GitHub&lt;/a&gt;. Use the following commands:&lt;/p&gt; &lt;pre&gt; &lt;code class="lang-bash"&gt; bash $ git clone https://github.com/go-delve/delve $ cd delve $ go install github.com/go-delve/delve/cmd/dlv &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;Keep the debugger running in order to debug the application on the remote server from your local system using the VS Code editor and the Remote - SSH extension.&lt;/p&gt; &lt;h2&gt;Configuration&lt;/h2&gt; &lt;p&gt;This section creates an example application to explain the debugging process step by step. We'll look at the repository and the configuration you need in order to debug the application interactively in a Kubernetes cluster.&lt;/p&gt; &lt;h3&gt;Repository&lt;/h3&gt; &lt;p&gt;Download an example Go application from &lt;a href="https://github.com/alknopfler/go-remote-debug-delve.git"&gt;the GitHub repository&lt;/a&gt;. The contents of this repository are:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; alknopfler:alkmini : ~/projects/src/github.com/alknopfler/go-remote-debug-delve {master} $ tree . . |-- .vscode | |-- settings.json | |-- launch.json ├── docker │ └── debug │ └── Dockerfile ├── go.mod ├── k8s │ └── deployment.yml ├── main.go ├── Makefile ├── README.md └── skaffold.yaml &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The key contents are:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;docker&lt;/code&gt; folder: Contains the Dockerfile to generate the image, which we'll push to the &lt;a href="https://quay.io/"&gt;Quay.io registry&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;&lt;code&gt;k8s&lt;/code&gt; folder: Contains the manifest that describes application deployment.&lt;/li&gt; &lt;li&gt;&lt;code&gt;Main.go&lt;/code&gt;: The application's main code file.&lt;/li&gt; &lt;li&gt;&lt;code&gt;Skaffold.yaml&lt;/code&gt;: The configuration file used to build and deploy the application.&lt;/li&gt; &lt;li&gt;&lt;code&gt;.vscode/launch.json&lt;/code&gt;: The configuration for the cloud code extension.&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;Configure Cloud Code&lt;/h3&gt; &lt;p&gt;Open the &lt;code&gt;.vscode/launch.json&lt;/code&gt; file and add the configuration options marked by arrows in Figure 3. I'll describe the options next.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/k8s-fig3.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/k8s-fig3.png?itok=d_QLgqEM" width="600" height="345" alt="Add configuration options for the Cloud Code extension." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3. Add configuration options for the Cloud Code extension. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;h4&gt;Attach (Go) to k8s Pod&lt;/h4&gt; &lt;p&gt;We use this option to attach to a running pod in the Kubernetes cluster in order to debug it. You can set a breakpoint in the code as long as the image was built with the Delve debugger installed. Debug the application by attaching to its pod selector and port, shown in the following configuration:&lt;/p&gt; &lt;pre&gt; &lt;code class="lang-yaml"&gt; yaml { "name": "Attach to Kubernetes Pod (Go)", "type": "cloudcode.kubernetes", "request": "attach", "language": "Go", "debugPort": 40000, "podSelector": { "app": "server-debug" }, "localRoot": "${workspaceFolder}", "remotePath": "", "remoteRoot": "/" } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Make sure to configure the &lt;code&gt;remotePath&lt;/code&gt; and &lt;code&gt;remoteRoot&lt;/code&gt; properties. If you make a mistake here, you will be able to attach to the pod but not debug it, because the breakpoint will be "unverified."&lt;/p&gt; &lt;h4&gt;Run/Debug Kubernetes App&lt;/h4&gt; &lt;p&gt;The configuration for this option follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="lang-yaml"&gt;`yaml { "name": "Kubernetes: Run/Debug", "type": "cloudcode.kubernetes", "request": "launch", "autoStop": false, "skaffoldConfig": "${workspaceFolder}/skaffold.yaml", "watch": true, "cleanUp": true, "portForward": true, "imageRegistry": "quay.io", "debug": [ { "image": "quay.io/amorgant/server-debug", "containerName": "server-debug", "sourceFileMap": { "${workspaceFolder}": "" } } ] }, &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Some points should be explained:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;autoStop&lt;/code&gt;: If you set this to &lt;code&gt;true&lt;/code&gt;, the debugging session stops automatically when the application terminates.&lt;/li&gt; &lt;li&gt;&lt;code&gt;SkaffoldConfig&lt;/code&gt;: This is the configuration file that continuously builds and deploys the application.&lt;/li&gt; &lt;li&gt;&lt;code&gt;watch&lt;/code&gt;: This is the most important option for debugging interactively. It notifies Skaffold of changes in your code, so that Skaffold can rebuild and redeploy the new image while you're debugging and recoding. Also, if you enable the &lt;code&gt;auto-save&lt;/code&gt; option, this process will be constantly running.&lt;/li&gt; &lt;li&gt;&lt;code&gt;cleanUp&lt;/code&gt;: This leaves the server in a clean state after your session. It destroys the containers and images created by Skaffold after you stop the debugger.&lt;/li&gt; &lt;li&gt;&lt;code&gt;portForward&lt;/code&gt;: This option allows you to run the debugger remotely by port forwarding to your local environment.&lt;/li&gt; &lt;li&gt;&lt;code&gt;debug/image&lt;/code&gt;: This is the image you will build with the Delve debugger installed, along with your application.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;In short, you can use the Cloud Code extension along with the "Attach (Go) to k8s Pod" option to debug a running pod. And if you change something in your code, Skaffold builds and deploys the new image to continue the debugging step. The combination of both options provides the magic to debug Kubernetes applications or operators remotely.&lt;/p&gt; &lt;h2&gt;Configure Skaffold&lt;/h2&gt; &lt;p&gt;&lt;a href="https://skaffold.dev/docs/pipeline-stages/"&gt;Skaffold&lt;/a&gt; is a very interesting tool for building and deploying your application directly using the Cloud Code extension you just installed. Just copy the manifest to create a pipeline for your application and run the Cloud Code extension to use the manifest. There are a number of interesting options that I'll describe shortly.&lt;/p&gt; &lt;p&gt;Figure 4 shows the steps Skaffold passes through to build and deploy an application. This process doesn't take place in real time, because the build step takes some time, but you can debug and rebuild iteratively without having to stop the debugger.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/k8s-fig4.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/k8s-fig4.png?itok=DSA1ScQ5" width="600" height="193" alt="Skaffold passes through several steps to automate a build and deployment." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4. Skaffold passes through several steps to automate a build and deployment. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;The configuration file we use in this example follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="lang-yaml"&gt;yaml apiVersion: skaffold/v2beta19 kind: Config build: artifacts: - image: quay.io/amorgant/server-debug buildpacks: builder: gcr.io/buildpacks/builder:v1 context: . sync: auto: true local: push: true deploy: kubectl: manifests: - k8s/deployment.yml &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For our build step, Skaffold supports a number of &lt;a href="https://skaffold.dev/docs/pipeline-stages/builders/"&gt;builders&lt;/a&gt;, which include common tools like Dockerfile, Maven, and &lt;a href="https://docs.cloudfoundry.org/buildpacks/"&gt;Buildpacks&lt;/a&gt;, along with your own custom scripts. In our case, we're going to use Buildpacks, which automatically detects your Dockerfile and uses it for the build:&lt;/p&gt; &lt;pre&gt; &lt;code class="lang-yaml"&gt; yaml buildpacks: builder: gcr.io/buildpacks/builder:v1 &lt;/code&gt; &lt;/pre&gt; &lt;p&gt;For a large project where several build steps have complex Makefiles, you could use a configuration like this one:&lt;/p&gt; &lt;pre&gt; &lt;code class="lang-yaml"&gt; yaml buildpacks: custom: buildCommand: | sudo -S skipper make update-debug-minimal docker tag quay.io/ocpmetal/assisted-service:latest quay.io/amorgant/assisted-service:latest docker push quay.io/amorgant/assisted-service:latest sudo -S skipper make deploy-all &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Also, you could build using your Dockerfile specification, like this:&lt;/p&gt; &lt;pre&gt; &lt;code class="lang-yaml"&gt; yaml docker: dockerfile: deploy/Dockerfile &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For the deployment step, Skaffold supports several &lt;a href="https://skaffold.dev/docs/pipeline-stages/deployers/"&gt;deployers&lt;/a&gt;: Kubernetes, Helm, Kustomize, and Docker.&lt;/p&gt; &lt;h2&gt;Dockerfile configuration for debugging&lt;/h2&gt; &lt;p&gt;To debug your application, you need to build its image to include Delve. That way, you can run the application through the &lt;code&gt;dlv&lt;/code&gt; command's entry point:&lt;/p&gt; &lt;pre&gt; &lt;code class="lang-Dockerfile"&gt; Dockerfile FROM golang:1.16 AS build WORKDIR / COPY . . RUN CGO_ENABLED=0 go get -ldflags "-s -w -extldflags '-static'" github.com/go-delve/delve/cmd/dlv RUN CGO_ENABLED=0 go build -gcflags "all=-N -l" -o ./app FROM alpine WORKDIR / COPY . . COPY --from=build /go/bin/dlv dlv COPY --from=build /app app ENTRYPOINT [ "/dlv" , "--listen=:40000", "--headless=true", "--api-version=2", "--accept-multiclient", "exec", "/app"]] &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The entry point launches the application using the &lt;code&gt;dlv&lt;/code&gt; command so you can debug the application on the remote server.&lt;/p&gt; &lt;h2&gt;The Kubernetes deployment&lt;/h2&gt; &lt;p&gt;This is a basic deployment for the Kubernetes application. It's a simple deployment with a single container using the image we've just built:&lt;/p&gt; &lt;pre&gt; &lt;code class="lang-yaml"&gt;yaml apiVersion: apps/v1 kind: Deployment metadata: name: server-debug spec: selector: matchLabels: app: server-debug template: metadata: labels: app: server-debug spec: containers: - name: server-debug image: quay.io/amorgant/server-debug imagePullPolicy: Always resources: requests: memory: "128Mi" cpu: "100m" limits: memory: "256Mi" cpu: "500m" ports: - containerPort: 8080 &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Demo: Debugging Kubernetes remotely&lt;/h2&gt; &lt;p&gt;Once you have the whole configuration ready, open the Cloud Code extension and follow the steps in this section.&lt;/p&gt; &lt;p&gt;First, verify that the cluster is ready and that you can get access to its resources from VS Code and the Cloud Code extension, as shown in Figure 5.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/k8s-fig5.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/k8s-fig5.png?itok=__LpSCHk" width="353" height="432" alt="The deployments and pods are now available to VS Code." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5. The deployments and pods are available to VS Code. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Next, set a breakpoint in the code, as shown in Figure 6.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/k8s-fig6.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/k8s-fig6.png?itok=P43lDTw6" width="600" height="243" alt="Setting a breakpoint in Main.go." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 6. Set a breakpoint in Main.go. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Now, click the &lt;strong&gt;Debug on Kubernetes&lt;/strong&gt; button to start the process, as shown in Figure 7.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/k8s-fig7.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/k8s-fig7.png?itok=GIG7-HUt" width="545" height="427" alt="The Debug on Kubernetes button is available in the Cloud Code extension." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 7. The Debug on Kubernetes button is available in the Cloud Code extension. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Once the application starts, it is run through the debugger, as shown in the following video.&lt;/p&gt; &lt;div class="video-embed-field-provider-youtube video-embed-field-responsive-video"&gt; &lt;/div&gt; &lt;h2&gt;Limitations and a quick fix&lt;/h2&gt; &lt;p&gt;To make this process work, you need to copy the project inside the Dockerfile because the debugger needs access to the stack to know which is the trace to debug it. The following should provide what you need:&lt;/p&gt; &lt;pre&gt; &lt;code&gt; WORKDIR / COPY . . &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Resources&lt;/h2&gt; &lt;p&gt;Some of the main tools mentioned in this article are:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-ssh"&gt;VScode Remote Explorer&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://marketplace.visualstudio.com/items?itemName=GoogleCloudTools.cloudcode"&gt;Cloud Code extension&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/go-delve/delve/tree/master/Documentation/installation"&gt;Delve Go debugger&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://skaffold.dev/docs/pipeline-stages/builders/"&gt;Skaffold builders&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=d-P5wCdCwrQ"&gt;Video of debug session&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Acknowledgements&lt;/h2&gt; &lt;p&gt;I'd like to thank two people who inspired and helped me with this example application.&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Special thanks to &lt;a href="https://github.com/danielchg"&gt;@dchavero&lt;/a&gt; for help with the configuration of the environment.&lt;/li&gt; &lt;li&gt;Thanks also to &lt;a href="https://github.com/antelman107"&gt;antelman107&lt;/a&gt; for the application, which made me think about creating this article.&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/12/13/remote-debugging-kubernetes-using-vs-code" title="Remote debugging on Kubernetes using VS Code"&gt;Remote debugging on Kubernetes using VS Code&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Alberto Morgante Medina</dc:creator><dc:date>2021-12-13T07:00:00Z</dc:date></entry><entry><title type="html">WildFly Impact of the Apache Log4j Security Vulnerabilities</title><link rel="alternate" href="https://wildfly.org//news/2021/12/13/Log4j-CVEs/" /><author><name>Brian Stansberry</name></author><id>https://wildfly.org//news/2021/12/13/Log4j-CVEs/</id><updated>2021-12-13T00:00:00Z</updated><content type="html">WildFly users are of course interested in the impact of the recently disclosed security vulnerabilities related to Apache Log4j. On Friday the @WildFlyAS Twitter account . In this post I want to provide further details, information on how users who package the log4j-core artifact in their WildFly application deployments can mitigate the risk, and provide information on how the affects WildFly. CVE-2021-44228 is a critical impact zero-day vulnerability in the Apache Log4j log4j-core library whereby a remote attacker who can control log messages or log message parameters can execute arbitrary code on a server via a JNDI lookup. I won’t get into the technical details of the exploit here; instead I refer you to . This vulnerability is in code in the Log4j 2 org.apache.logging.log4j:log4j-core artifact. The WildFly application server project does not ship this artifact, and it never has. So, the only way an application running on WildFly would be vulnerable to the CVE-2021-44228 vulnerability is if the log4j-core artifact has been added to the server installation, either via a user-provided JBoss Modules module, or more likely by packaging log4j-core in an application deployment artifact. Note that since WildFly 22, WildFly does ship the Log4j 2 org.apache.logging.log4j:log4j-api artifact, and up to WildFly 26.0.0.Beta1 the version of that artifact matches the CVE-2021-44228 CPE. However, the log4j-api artifact does not contain the vulnerable code.. Note that even though the artifact on WildFly 26.0.0.Beta1 does not have the vulnerability, to help avoid confusion the upcoming 26.0.0.Final release will move to the 2.15.0 version of the artifact, which does not match the CVE-2021-44228 CPE. MITIGATION STRATEGIES If your application does include the log4j-core artifact, the following are steps you can take to mitigate any vulnerability: SET FORMATMSGNOLOOKUPS=TRUE Since its 2.10 release, Log4j provides a configuration option that lets you turn off the JNDI lookup behavior that results in the vulnerability. To use this, update the $WILDFLY_HOME/bin/standalone.conf or $WILDFLY_HOME/bin/domain.conf file (or, for Windows users, the .bat or .ps1 variants of those) to add -Dlog4j2.formatMsgNoLookups=true to the value of the JAVA_OPTS environment variable. (Which file you update depends on whether you are running a standalone server or a domain mode host.) Note that if you are using a version of log4j-core prior to 2.10 this will have no effect. If you’re on a recent enough log4j-core version setting this is the quickest mitigation, but whether you can use it or not as soon as you can you should also… UPGRADE LOG4J-CORE TO THE 2.15.0 OR LATER RELEASE The Apache Log4j project has that fixes the flaw. If you are packaging log4j-core in your application we recommend updating your deployment artifact to 2.15.0 or later as soon as possible. Note that I’ve seen user reports that upgrading to 2.15.0 in a deployment is problematic when the container is providing an earlier release of the log4j-api artifact. This should not be a problem if you are following the . If you are packaging log4j-core, you should exclude any module dependency on the log4-api provided by WildFly and instead package log4j-api in your deployment. CVE-2021-4104 Recently Red Hat , in this case Log4j 1. They rated the impact of this vulnerability as "Moderate impact", unlike their which was rated as "Critical impact". (For more on the difference between "Critical" and "Moderate", see .) CVE-2021-4104 has some surface similarity to CVE-2021-44228, in that both relate to a logging library doing a JNDI lookup, with a risk that that library could be fooled into doing a lookup and deserialization of content from an untrustworthy source. In the CVE-2021-4104 case the lookups can be performed by the org.apache.log4j.net.JMSAppender class, a class that is used if an application configures a log appender meant to write to an external JMS topic. The JMSAppender lookup is quite different from the CVE-2021-44228 one though, in that the name being looked up is meant to be of a string provided as part of the appender’s configuration, not one that is incorporated in a log message. It is significantly easier to get a server to inject a malicious string into a log message than it is to inject one into the container configuration. The latter would typically require some sort of privileged access to the server. This increased difficulty of exploit is one of the when deciding the severity of a vulnerability. WildFly does not ship Apache Log4j 1 itself, but the org.jboss.logmanager:log4j-jboss-logmanager artifact we ship shades the Log4j 1 classes, including JMSAppender. JMSAppender has been present in WildFly or JBoss AS at least as far back as JBoss AS 7.1, and probably much farther. However, our attempts to configure WildFly to use the JMSAppender have been unsuccessful, failing before the JMSAppender code reaches a point where it does any JNDI lookup. This is because the JBoss Modules module that packages org.jboss.logmanager:log4j-jboss-logmanager does not include a dependency on the module that provides the javax.naming package, resulting in a ClassNotFoundException if the class is used. So at this point we don’t see an exploit involving normal modular use of the org.jboss.logmanager:log4j-jboss-logmanager artifact we ship. Exploits would likely require the use of reflection. If you package Apache Log4j 1 in your application, be careful not to expose to untrusted callers any mechanism that would allow them to access the JMSAppender class or configure instances of it. Which is the right thing to do in general! Running with the JVM security manager enabled is another way to defend against attacks based on getting your application to make unexpected calls to external systems. If you have any questions about any of the above, I encourage you to ask on the . Best regards, Brian</content><dc:creator>Brian Stansberry</dc:creator></entry><entry><title>Tracing hardware offload in Open vSwitch</title><link rel="alternate" href="https://developers.redhat.com/articles/2021/12/10/tracing-hardware-offload-open-vswitch" /><author><name>Abhiram R N</name></author><id>81c397b7-ec46-490b-b0b4-02b026be1d2e</id><updated>2021-12-10T07:00:00Z</updated><published>2021-12-10T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://www.openvswitch.org"&gt;Open vSwitch (OVS)&lt;/a&gt; is an open source framework for software-defined networking (SDN) and is &lt;a href="https://superuser.openstack.org/articles/openvswitch-openstack-sdn/"&gt;useful in virtualized environments&lt;/a&gt;. Just like conventional network stacks, OVS can offload tasks to the hardware running on the network interface card (NIC) to speed up the processing of network packets.&lt;/p&gt; &lt;p&gt;However, dozens of functions are invoked in a chain to achieve hardware offload. This article takes you through the chain of functions to help you debug networking problems with OVS.&lt;/p&gt; &lt;p&gt;This article assumes that you understand the basics of OVS and hardware offload. To accompany your study of this article, you should be familiar with network commands, particularly &lt;a href="https://developers.redhat.com/topics/linux/"&gt;Linux's&lt;/a&gt; &lt;a href="https://man7.org/linux/man-pages/man8/tc.8.html"&gt;&lt;code&gt;tc&lt;/code&gt; (traffic control) command&lt;/a&gt;, in order to dump traffic flows and see whether they are offloaded.&lt;/p&gt; &lt;p&gt;For the flow illustrated in this article, I used a &lt;a href="https://www.mellanox.com/"&gt;Mellanox&lt;/a&gt; NIC.&lt;/p&gt; &lt;h2&gt;The start of a network transmission&lt;/h2&gt; &lt;p&gt;Let's start our long journey from an add/modify OVS operation to the hardware drivers with the first few functions called. Figure 1 shows each function at the beginning of the process, and the file in OVS that defines the function.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/start_0.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/start_0.png?itok=vj-7CJao" width="826" height="507" alt="OVS launches the chain of functions that eventually lead to hardware offload." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1. OVS launches the chain of functions that eventually lead to hardware offload. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;There are two ways that flows can be installed in the datapath. One is &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;dpctl_add_flow&lt;/code&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;, which can be used to manually inject the flow to the datapath as shown in Figure 1. But &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;ovs-dpctl&lt;/code&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; is not a common way of injecting datapath flows. Typically what happens is that the handler thread in OVS receives an upcall from &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;dpif&lt;/code&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;, processes it, and installs the flow via &lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;code&gt;dpif_operate()&lt;/code&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt;&lt;span&gt; as shown in Figure 2.&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/pic2_new.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/pic2_new.png?itok=17HjTMI7" width="638" height="453" alt="Figure 2. udpif_upcall_handler receives the upcall from dpif and installs the flow." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2. udpif_upcall_handler receives the upcall from dpif and installs the flow. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;OVS offload operations&lt;/h2&gt; &lt;p&gt;The &lt;code&gt;dpif_netlink_operate&lt;/code&gt; function is registered to the function pointer &lt;code&gt;dpif-&gt;dpif_class-&gt;operate&lt;/code&gt;. Calling the function leads to the call stack in Figure 3.&lt;/p&gt; &lt;figure class="rhd-u-has-filter-caption" role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/pic3_new_0.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/pic3_new_0.png?itok=odbOwwQr" width="807" height="434" alt="A put operation invokes the function assigned to a function pointer for that purpose." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 3. A put operation invokes the function assigned to a function pointer for that purpose.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;OVS's &lt;code&gt;/lib/netdev-offload.c&lt;/code&gt; file defines a &lt;code&gt;netdev_register_flow_api_provider&lt;/code&gt; function. The chain of calls continues through a function pointer registered as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;netdev_register_flow_api_provider(&amp;netdev_offload_tc);&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;netdev_tc_flow_put&lt;/code&gt; function is assigned to the &lt;code&gt;.flow_put&lt;/code&gt; struct member as shown in the following excerpt:&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;const struct netdev_flow_api netdev_offload_tc = { .type = "linux_tc", … .flow_put = netdev_tc_flow_put, … };&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;After the call reaches &lt;code&gt;netdev_tc_flow_put&lt;/code&gt;, the chain of calls continues as shown in Figure 4.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/after.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/after.png?itok=EGk4koeN" width="538" height="693" alt="Another sequence eventually calls sendmsg." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4. Another sequence eventually calls sendmsg. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;h2&gt;Sequence from a tc command&lt;/h2&gt; &lt;p&gt;Let's leave our pursuit of offloading in the chain of OVS calls for a moment and look at a more conventional sequence of calls. Without OVS in the picture, a call from the &lt;code&gt;tc&lt;/code&gt; utility proceeds as shown in Figure 5.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/tc.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/tc.png?itok=w70Z-LU5" width="846" height="765" alt="You can run a tc command and trace the sequence from sendmsg." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5. You can run a tc command and trace the sequence from sendmsg. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Whether &lt;code&gt;sendmsg&lt;/code&gt; is issued from &lt;code&gt;tc&lt;/code&gt;, from OVS, or from another sender, the message goes to the kernel and then to the hardware driver.&lt;/p&gt; &lt;h2&gt;The call to sendmsg&lt;/h2&gt; &lt;p&gt;Now let's continue from where we had paused earlier in &lt;code&gt;sendmsg&lt;/code&gt;. The chain of functions continues as shown in Figure 6.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/sendmsg_1.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/sendmsg_1.png?itok=1W5-5abG" width="793" height="671" alt="sendmsg invokes functions from the Routing Netlink (rtnl) subsystem." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 6. sendmsg invokes functions from the Routing Netlink (rtnl) subsystem. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;The Linux kernel registers the following functions to Routing Netlink (&lt;code&gt;rtnl&lt;/code&gt;) subsystem:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;&lt;code&gt;tc_new_tfilter&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;tc_del_tfilter&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;tc_get_tfilter&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;code&gt;tc_ctl_chain&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;These functions are registered by calling &lt;code&gt;rtnl_register&lt;/code&gt; in the &lt;code&gt;net/sched/cls_api.c&lt;/code&gt; file. The &lt;code&gt;RTM_NEWCHAIN&lt;/code&gt;, &lt;code&gt;RTM_GETCHAIN&lt;/code&gt;, and &lt;code&gt;RTM_DELCHAIN&lt;/code&gt; operations take place in &lt;code&gt;tc_ctl_chain&lt;/code&gt;. In turn, &lt;code&gt;rtnl_register&lt;/code&gt; invokes &lt;code&gt;rtnl_register_internal&lt;/code&gt;, defined in &lt;code&gt;net/core/rtnetlink.c&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The sequence continues based on functions registered to the &lt;code&gt;rtnl&lt;/code&gt; subsystem. &lt;code&gt;tc_new_tfilter&lt;/code&gt;, defined in &lt;code&gt;net/sched/cls_api.c&lt;/code&gt;, invokes the function pointer registered to &lt;code&gt;tp-&gt;ops-&gt;change&lt;/code&gt;, and ends up calling &lt;code&gt;fl_change&lt;/code&gt; from the &lt;code&gt;net/sched/cls_flower.c&lt;/code&gt; file.&lt;/p&gt; &lt;p&gt;&lt;code&gt;fl_change&lt;/code&gt; checks whether the &lt;code&gt;skip_hw&lt;/code&gt; or &lt;code&gt;skip_sw&lt;/code&gt; policy is present. If the &lt;code&gt;tc-policy&lt;/code&gt; is &lt;code&gt;skip_hw&lt;/code&gt;, the flow is just added to &lt;code&gt;tc&lt;/code&gt; and the function returns.&lt;/p&gt; &lt;p&gt;Figure 7 takes a deeper look into the &lt;code&gt;fl_change&lt;/code&gt; function. It has changed somewhat in the latest kernel version, but the control flow is pretty much the same as the one shown in the figure.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/change_0.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/change_0.png?itok=rcWViiDl" width="642" height="735" alt="The fl_change function checks for skip_sw and skip_hw." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 7. The fl_change function checks for skip_sw and skip_hw. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;If &lt;code&gt;tc-policy&lt;/code&gt; is unset or &lt;code&gt;skip_sw&lt;/code&gt;, the call sequence tries to add the flow to the hardware. Because we are interested in flows that get offloaded to hardware, we continue our journey further. The sequence of calls is the following, invoking functions &lt;/p&gt; &lt;p&gt;&lt;code&gt;fl_hw_replace_filter (cls_flower.c) --&gt; tc_setup_cb_add (cls_api.c) --&gt; __tc_setup_cb_call (cls_api.c)&lt;/code&gt;&lt;/p&gt; &lt;h2&gt;Finally, in the device driver&lt;/h2&gt; &lt;p&gt;From here, the sequence goes to the hardware driver that was registered for the sender when Linux set up traffic control as part of its init sequence. For instance, the following code defines our Mellanox driver as the recipient of the message:&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;.ndo_setup_tc = mlx5e_setup_tc,&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;mlx5e_setup_tc&lt;/code&gt; function issues the following call to register the socket buffer's control block (CB):&lt;/p&gt; &lt;pre&gt; &lt;code class="cpp"&gt;flow_block_cb_setup_simple(type_data, &amp;mlx5e_block_cb_list, mlx5e_setup_tc_block_cb, priv, priv, true);&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In our case, the Mellanox hardware function named &lt;code&gt;mlx5e_setup_tc_block_cb&lt;/code&gt; gets called.&lt;/p&gt; &lt;p&gt;So now we have reached the Mellanox driver code. A few more calls and we can see how the flow rule is added to the flow table for hardware offload (Figure 8).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/offload.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/offload.png?itok=JNuSYfgE" width="956" height="764" alt="The Mellanox hardware driver checks flags to add the flow." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 8. The Mellanox hardware driver checks flags to add the flow. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;The &lt;code&gt;drivers/net/ethernet/mellanox/mlx5/core/fs_cmd.c&lt;/code&gt; registers the following function, and the sequence continues as shown in Figure 9.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/driver.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/driver.png?itok=t1nwn4bs" width="1015" height="393" alt="The Mellanox driver adds the flow to the hardware." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 9. The Mellanox driver adds the flow to the hardware. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;pre&gt; &lt;code class="cpp"&gt;.create_fte = mlx5_cmd_create_fte,&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The final function in Figure 9 invokes a command that adds the flow rule to the hardware. With this result, we have reached our destination.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;I hope this helps you understand what happens while adding a flow for hardware offload, and helps you troubleshoot problems you might encounter. To learn more about the basics of Open vSwitch hardware offload, I recommend reading &lt;a href="https://hareshkhandelwal.blog/2020/03/11/lets-understand-the-openvswitch-hardware-offload/"&gt;Haresh Khandelwal's blog post&lt;/a&gt; on the subject.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/12/10/tracing-hardware-offload-open-vswitch" title="Tracing hardware offload in Open vSwitch"&gt;Tracing hardware offload in Open vSwitch&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Abhiram R N</dc:creator><dc:date>2021-12-10T07:00:00Z</dc:date></entry><entry><title type="html">Quarkus 2.5.2.Final released - Maintenance release</title><link rel="alternate" href="https://quarkus.io/blog/quarkus-2-5-2-final-released/" /><author><name>Guillaume Smet</name></author><id>https://quarkus.io/blog/quarkus-2-5-2-final-released/</id><updated>2021-12-10T00:00:00Z</updated><content type="html">We just released Quarkus 2.5.2.Final, a maintenance release for our 2.5 release train containing bugfixes and documentation improvements. It is a safe upgrade for anyone already using 2.5. If you are not using 2.5 already, please refer to the 2.5 migration guide. Full changelog You can get the full changelog...</content><dc:creator>Guillaume Smet</dc:creator></entry><entry><title type="html">DMN example application with Quarkus</title><link rel="alternate" href="http://www.mastertheboss.com/bpm/kogito/dmn-example-application-with-quarkus/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=dmn-example-application-with-quarkus" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/bpm/kogito/dmn-example-application-with-quarkus/?utm_source=rss&amp;utm_medium=rss&amp;utm_campaign=dmn-example-application-with-quarkus</id><updated>2021-12-09T17:30:21Z</updated><content type="html">In our first tutorial about DMN – Getting started with Decision Models (DMN) – we have covered the foundation of Decision Models and the key components in it. In this follow up article we will design and create an example application which exposes a simple Decision Model through Quarkus REST Services. Designing the Decision Model ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry></feed>
